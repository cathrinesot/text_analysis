{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import log_loss, confusion_matrix\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import ast\n",
    "from datetime import datetime\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (1,2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "      <th>tag</th>\n",
       "      <th>df</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>num_wds</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>uniq_wds</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>char_count</th>\n",
       "      <th>numbers</th>\n",
       "      <th>mtld</th>\n",
       "      <th>msttr</th>\n",
       "      <th>hdd</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>perc_uniq</th>\n",
       "      <th>avg_sent</th>\n",
       "      <th>caps_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48527</th>\n",
       "      <td>58100</td>\n",
       "      <td>1.96551e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-28 00:00:00</td>\n",
       "      <td>28-08-2016 Turkish Bombardment Kills 20 Civili...</td>\n",
       "      <td>Turkish Bombardment Kills 20 Civilians in Syria</td>\n",
       "      <td>manar</td>\n",
       "      <td>1</td>\n",
       "      <td>svdc</td>\n",
       "      <td>28082016 turkish bombardment kills 20 civilian...</td>\n",
       "      <td>240</td>\n",
       "      <td>40</td>\n",
       "      <td>114</td>\n",
       "      <td>28082016 turkish bombardment kill 20 civilian ...</td>\n",
       "      <td>1446</td>\n",
       "      <td>6</td>\n",
       "      <td>13.924646</td>\n",
       "      <td>0.555714</td>\n",
       "      <td>0.403273</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48528</th>\n",
       "      <td>58101</td>\n",
       "      <td>1.96551e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-01 00:00:00</td>\n",
       "      <td>17-08-2016 Martyrs as Terrorists Shell Aleppos...</td>\n",
       "      <td>Martyrs as Terrorists Shell Aleppos Salah Eddin</td>\n",
       "      <td>manar</td>\n",
       "      <td>1</td>\n",
       "      <td>svdc</td>\n",
       "      <td>17082016 martyrs as terrorists shell aleppos s...</td>\n",
       "      <td>113</td>\n",
       "      <td>33</td>\n",
       "      <td>64</td>\n",
       "      <td>17082016 martyr a terrorist shell aleppo salah...</td>\n",
       "      <td>726</td>\n",
       "      <td>1</td>\n",
       "      <td>12.476640</td>\n",
       "      <td>0.517143</td>\n",
       "      <td>0.395255</td>\n",
       "      <td>5.504425</td>\n",
       "      <td>0.566372</td>\n",
       "      <td>5.504425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48529</th>\n",
       "      <td>58102</td>\n",
       "      <td>1.96551e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-03 00:00:00</td>\n",
       "      <td>03-08-2016 Chemical Attack Kills Five Syrians ...</td>\n",
       "      <td>Chemical Attack Kills Five Syrians in Aleppo SANA</td>\n",
       "      <td>manar</td>\n",
       "      <td>0</td>\n",
       "      <td>svdc</td>\n",
       "      <td>03082016 chemical attack kills five syrians in...</td>\n",
       "      <td>224</td>\n",
       "      <td>28</td>\n",
       "      <td>130</td>\n",
       "      <td>03082016 chemical attack kill five syrian in a...</td>\n",
       "      <td>1418</td>\n",
       "      <td>2</td>\n",
       "      <td>13.552202</td>\n",
       "      <td>0.539636</td>\n",
       "      <td>0.397377</td>\n",
       "      <td>5.388393</td>\n",
       "      <td>0.580357</td>\n",
       "      <td>5.388393</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48530</th>\n",
       "      <td>58103</td>\n",
       "      <td>1.96551e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-01 00:00:00</td>\n",
       "      <td>01-08-2016 5 Killed as Russian Military Choppe...</td>\n",
       "      <td>5 Killed as Russian Military Chopper Shot down...</td>\n",
       "      <td>manar</td>\n",
       "      <td>1</td>\n",
       "      <td>svdc</td>\n",
       "      <td>01082016 5 killed as russian military chopper ...</td>\n",
       "      <td>244</td>\n",
       "      <td>44</td>\n",
       "      <td>121</td>\n",
       "      <td>01082016 5 killed a russian military chopper s...</td>\n",
       "      <td>1483</td>\n",
       "      <td>1</td>\n",
       "      <td>13.401570</td>\n",
       "      <td>0.535862</td>\n",
       "      <td>0.392486</td>\n",
       "      <td>5.159836</td>\n",
       "      <td>0.495902</td>\n",
       "      <td>5.159836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48531</th>\n",
       "      <td>58104</td>\n",
       "      <td>1.96551e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-04 00:00:00</td>\n",
       "      <td>April 6 2017 Syrian Army Kills 48 ISIL Terrori...</td>\n",
       "      <td>Syrian Army Kills 48 ISIL Terrorists in Deir E...</td>\n",
       "      <td>manar</td>\n",
       "      <td>1</td>\n",
       "      <td>svdc</td>\n",
       "      <td>april 6 2017 syrian army kills 48 isil terrori...</td>\n",
       "      <td>408</td>\n",
       "      <td>21</td>\n",
       "      <td>173</td>\n",
       "      <td>april 6 2017 syrian army kill 48 isil terroris...</td>\n",
       "      <td>2565</td>\n",
       "      <td>8</td>\n",
       "      <td>12.903470</td>\n",
       "      <td>0.526800</td>\n",
       "      <td>0.386315</td>\n",
       "      <td>5.366748</td>\n",
       "      <td>0.424020</td>\n",
       "      <td>5.366748</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index           id author                 date  \\\n",
       "48527  58100  1.96551e+09    NaN  2016-08-28 00:00:00   \n",
       "48528  58101  1.96551e+09    NaN  2016-08-01 00:00:00   \n",
       "48529  58102  1.96551e+09    NaN  2016-08-03 00:00:00   \n",
       "48530  58103  1.96551e+09    NaN  2016-08-01 00:00:00   \n",
       "48531  58104  1.96551e+09    NaN  2017-04-04 00:00:00   \n",
       "\n",
       "                                                    text  \\\n",
       "48527  28-08-2016 Turkish Bombardment Kills 20 Civili...   \n",
       "48528  17-08-2016 Martyrs as Terrorists Shell Aleppos...   \n",
       "48529  03-08-2016 Chemical Attack Kills Five Syrians ...   \n",
       "48530  01-08-2016 5 Killed as Russian Military Choppe...   \n",
       "48531  April 6 2017 Syrian Army Kills 48 ISIL Terrori...   \n",
       "\n",
       "                                                   title source tag    df  \\\n",
       "48527    Turkish Bombardment Kills 20 Civilians in Syria  manar   1  svdc   \n",
       "48528    Martyrs as Terrorists Shell Aleppos Salah Eddin  manar   1  svdc   \n",
       "48529  Chemical Attack Kills Five Syrians in Aleppo SANA  manar   0  svdc   \n",
       "48530  5 Killed as Russian Military Chopper Shot down...  manar   1  svdc   \n",
       "48531  Syrian Army Kills 48 ISIL Terrorists in Deir E...  manar   1  svdc   \n",
       "\n",
       "                                               tokenized  num_wds  difficulty  \\\n",
       "48527  28082016 turkish bombardment kills 20 civilian...      240          40   \n",
       "48528  17082016 martyrs as terrorists shell aleppos s...      113          33   \n",
       "48529  03082016 chemical attack kills five syrians in...      224          28   \n",
       "48530  01082016 5 killed as russian military chopper ...      244          44   \n",
       "48531  april 6 2017 syrian army kills 48 isil terrori...      408          21   \n",
       "\n",
       "       uniq_wds                                         lemmatized  \\\n",
       "48527       114  28082016 turkish bombardment kill 20 civilian ...   \n",
       "48528        64  17082016 martyr a terrorist shell aleppo salah...   \n",
       "48529       130  03082016 chemical attack kill five syrian in a...   \n",
       "48530       121  01082016 5 killed a russian military chopper s...   \n",
       "48531       173  april 6 2017 syrian army kill 48 isil terroris...   \n",
       "\n",
       "       char_count  numbers       mtld     msttr       hdd  avg_word  \\\n",
       "48527        1446        6  13.924646  0.555714  0.403273  5.125000   \n",
       "48528         726        1  12.476640  0.517143  0.395255  5.504425   \n",
       "48529        1418        2  13.552202  0.539636  0.397377  5.388393   \n",
       "48530        1483        1  13.401570  0.535862  0.392486  5.159836   \n",
       "48531        2565        8  12.903470  0.526800  0.386315  5.366748   \n",
       "\n",
       "       perc_uniq  avg_sent  caps_body  \n",
       "48527   0.475000  5.125000          0  \n",
       "48528   0.566372  5.504425          0  \n",
       "48529   0.580357  5.388393          0  \n",
       "48530   0.495902  5.159836          0  \n",
       "48531   0.424020  5.366748          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"fakenews1.csv\" )\n",
    "pd.set_option(\"display.max_columns\",100)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'id', 'author', 'date', 'text', 'title', 'source', 'tag', 'df',\n",
       "       'tokenized', 'num_wds', 'difficulty', 'uniq_wds', 'lemmatized',\n",
       "       'char_count', 'numbers', 'mtld', 'msttr', 'hdd', 'avg_word',\n",
       "       'perc_uniq', 'avg_sent', 'caps_body'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>emotion</th>\n",
       "      <th>word</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abacus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandon</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandonment</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "emotion         word  anger  anticipation  disgust  fear  joy  negative  \\\n",
       "0                NaN    0.0           0.0      0.0   0.0  0.0       0.0   \n",
       "1             abacus    NaN           NaN      NaN   NaN  NaN       NaN   \n",
       "2            abandon    0.0           0.0      0.0   1.0  0.0       1.0   \n",
       "3          abandoned    1.0           0.0      0.0   1.0  0.0       1.0   \n",
       "4        abandonment    1.0           0.0      0.0   1.0  0.0       1.0   \n",
       "\n",
       "emotion  positive  sadness  surprise  trust  \n",
       "0             0.0      0.0       0.0    0.0  \n",
       "1             NaN      0.0       0.0    1.0  \n",
       "2             0.0      1.0       0.0    0.0  \n",
       "3             0.0      1.0       0.0    0.0  \n",
       "4             0.0      1.0       1.0    0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"../../Lexicons/NRC-emotion-lexicon-wordlevel-alphabetized-v0.92.txt\"\n",
    "emolex_df = pd.read_csv(filepath,  names=[\"word\", \"emotion\", \"association\"], skiprows=45, sep='\\t')\n",
    "emolex_df = emolex_df.pivot(index='word', columns='emotion', values='association').reset_index()\n",
    "emolex_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NaN</th>\n",
       "      <th>abacus</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abate</th>\n",
       "      <th>abatement</th>\n",
       "      <th>abba</th>\n",
       "      <th>abbot</th>\n",
       "      <th>abbreviate</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abdominal</th>\n",
       "      <th>abduction</th>\n",
       "      <th>aberrant</th>\n",
       "      <th>aberration</th>\n",
       "      <th>abeyance</th>\n",
       "      <th>abhor</th>\n",
       "      <th>abhorrent</th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>abject</th>\n",
       "      <th>ablation</th>\n",
       "      <th>ablaze</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abode</th>\n",
       "      <th>abolish</th>\n",
       "      <th>abolition</th>\n",
       "      <th>abominable</th>\n",
       "      <th>abomination</th>\n",
       "      <th>aboriginal</th>\n",
       "      <th>abort</th>\n",
       "      <th>abortion</th>\n",
       "      <th>abortive</th>\n",
       "      <th>abound</th>\n",
       "      <th>abovementioned</th>\n",
       "      <th>abrasion</th>\n",
       "      <th>abroad</th>\n",
       "      <th>abrogate</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>abscess</th>\n",
       "      <th>absence</th>\n",
       "      <th>absent</th>\n",
       "      <th>absentee</th>\n",
       "      <th>absenteeism</th>\n",
       "      <th>absinthe</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolution</th>\n",
       "      <th>...</th>\n",
       "      <th>yank</th>\n",
       "      <th>yard</th>\n",
       "      <th>yarn</th>\n",
       "      <th>yaw</th>\n",
       "      <th>yawn</th>\n",
       "      <th>yawning</th>\n",
       "      <th>yea</th>\n",
       "      <th>year</th>\n",
       "      <th>yearbook</th>\n",
       "      <th>yearling</th>\n",
       "      <th>yearly</th>\n",
       "      <th>yearn</th>\n",
       "      <th>yearning</th>\n",
       "      <th>years</th>\n",
       "      <th>yeast</th>\n",
       "      <th>yell</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yellows</th>\n",
       "      <th>yelp</th>\n",
       "      <th>yeoman</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yesteryear</th>\n",
       "      <th>yew</th>\n",
       "      <th>yield</th>\n",
       "      <th>yielding</th>\n",
       "      <th>yogi</th>\n",
       "      <th>yoke</th>\n",
       "      <th>yolk</th>\n",
       "      <th>yon</th>\n",
       "      <th>yonder</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youth</th>\n",
       "      <th>zany</th>\n",
       "      <th>zap</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealot</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zebra</th>\n",
       "      <th>zenith</th>\n",
       "      <th>zephyr</th>\n",
       "      <th>zeppelin</th>\n",
       "      <th>zest</th>\n",
       "      <th>zip</th>\n",
       "      <th>zodiac</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoological</th>\n",
       "      <th>zoology</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 14181 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NaN  abacus  abandon  abandoned  abandonment  abate  abatement  abba  \\\n",
       "0  0.0     0.0      0.0        0.0          0.0    0.0        0.0   0.0   \n",
       "1  0.0     0.0      0.0        0.0          0.0    0.0        0.0   0.0   \n",
       "2  0.0     0.0      0.0        0.0          0.0    0.0        0.0   0.0   \n",
       "3  0.0     0.0      0.0        0.0          0.0    0.0        0.0   0.0   \n",
       "4  0.0     0.0      0.0        0.0          0.0    0.0        0.0   0.0   \n",
       "\n",
       "   abbot  abbreviate  abbreviation  abdomen  abdominal  abduction  aberrant  \\\n",
       "0    0.0         0.0           0.0      0.0        0.0        0.0       0.0   \n",
       "1    0.0         0.0           0.0      0.0        0.0        0.0       0.0   \n",
       "2    0.0         0.0           0.0      0.0        0.0        0.0       0.0   \n",
       "3    0.0         0.0           0.0      0.0        0.0        0.0       0.0   \n",
       "4    0.0         0.0           0.0      0.0        0.0        0.0       0.0   \n",
       "\n",
       "   aberration  abeyance  abhor  abhorrent  abide  ability  abject  ablation  \\\n",
       "0         0.0       0.0    0.0        0.0    0.0      0.0     0.0       0.0   \n",
       "1         0.0       0.0    0.0        0.0    0.0      0.0     0.0       0.0   \n",
       "2         0.0       0.0    0.0        0.0    0.0      0.0     0.0       0.0   \n",
       "3         0.0       0.0    0.0        0.0    0.0      0.0     0.0       0.0   \n",
       "4         0.0       0.0    0.0        0.0    0.0      0.0     0.0       0.0   \n",
       "\n",
       "   ablaze  abnormal  aboard  abode  abolish  abolition  abominable  \\\n",
       "0     0.0       0.0     0.0    0.0      0.0        0.0         0.0   \n",
       "1     0.0       0.0     0.0    0.0      0.0        0.0         0.0   \n",
       "2     0.0       0.0     0.0    0.0      0.0        0.0         0.0   \n",
       "3     0.0       0.0     0.0    0.0      0.0        0.0         0.0   \n",
       "4     0.0       0.0     0.0    0.0      0.0        0.0         0.0   \n",
       "\n",
       "   abomination  aboriginal  abort  abortion  abortive  abound  abovementioned  \\\n",
       "0          0.0         0.0    0.0       0.0       0.0     0.0             0.0   \n",
       "1          0.0         0.0    0.0       0.0       0.0     0.0             0.0   \n",
       "2          0.0         0.0    0.0       0.0       0.0     0.0             0.0   \n",
       "3          0.0         0.0    0.0       0.0       0.0     0.0             0.0   \n",
       "4          0.0         0.0    0.0       0.0       0.0     0.0             0.0   \n",
       "\n",
       "   abrasion  abroad  abrogate  abrupt  abruptly  abscess  absence  absent  \\\n",
       "0       0.0     0.0       0.0     0.0       0.0      0.0      0.0     0.0   \n",
       "1       0.0     0.0       0.0     0.0       0.0      0.0      0.0     0.0   \n",
       "2       0.0     0.0       0.0     0.0       0.0      0.0      0.0     0.0   \n",
       "3       0.0     0.0       0.0     0.0       0.0      0.0      0.0     0.0   \n",
       "4       0.0     0.0       0.0     0.0       0.0      0.0      0.0     0.0   \n",
       "\n",
       "   absentee  absenteeism  absinthe  absolute  absolution  ...  yank  yard  \\\n",
       "0       0.0          0.0       0.0       0.0         0.0  ...   0.0   0.0   \n",
       "1       0.0          0.0       0.0       0.0         0.0  ...   0.0   0.0   \n",
       "2       0.0          0.0       0.0       0.0         0.0  ...   0.0   0.0   \n",
       "3       0.0          0.0       0.0       0.0         0.0  ...   0.0   0.0   \n",
       "4       0.0          0.0       0.0       0.0         0.0  ...   0.0   0.0   \n",
       "\n",
       "   yarn  yaw  yawn  yawning  yea  year  yearbook  yearling  yearly  yearn  \\\n",
       "0   0.0  0.0   0.0      0.0  0.0   1.0       0.0       0.0     0.0    0.0   \n",
       "1   0.0  0.0   0.0      0.0  0.0   0.0       0.0       0.0     0.0    0.0   \n",
       "2   0.0  0.0   0.0      0.0  0.0   0.0       0.0       0.0     0.0    0.0   \n",
       "3   0.0  0.0   0.0      0.0  0.0   0.0       0.0       0.0     0.0    0.0   \n",
       "4   0.0  0.0   0.0      0.0  0.0   3.0       0.0       0.0     0.0    0.0   \n",
       "\n",
       "   yearning  years  yeast  yell  yellow  yellows  yelp  yeoman  yesterday  \\\n",
       "0       0.0    0.0    0.0   0.0     0.0      0.0   0.0     0.0        0.0   \n",
       "1       0.0    0.0    0.0   0.0     0.0      0.0   0.0     0.0        0.0   \n",
       "2       0.0    0.0    0.0   0.0     0.0      0.0   0.0     0.0        0.0   \n",
       "3       0.0    0.0    0.0   0.0     0.0      0.0   0.0     0.0        1.0   \n",
       "4       0.0    0.0    0.0   0.0     0.0      0.0   0.0     0.0        0.0   \n",
       "\n",
       "   yesteryear  yew  yield  yielding  yogi  yoke  yolk  yon  yonder  young  \\\n",
       "0         0.0  0.0    0.0       0.0   0.0   0.0   0.0  0.0     0.0    0.0   \n",
       "1         0.0  0.0    0.0       0.0   0.0   0.0   0.0  0.0     0.0    0.0   \n",
       "2         0.0  0.0    0.0       0.0   0.0   0.0   0.0  0.0     0.0    0.0   \n",
       "3         0.0  0.0    0.0       0.0   0.0   0.0   0.0  0.0     0.0    0.0   \n",
       "4         0.0  0.0    0.0       0.0   0.0   0.0   0.0  0.0     0.0    0.0   \n",
       "\n",
       "   younger  youth  zany  zap  zeal  zealot  zealous  zebra  zenith  zephyr  \\\n",
       "0      0.0    0.0   0.0  0.0   0.0     0.0      0.0    0.0     0.0     0.0   \n",
       "1      0.0    0.0   0.0  0.0   0.0     0.0      0.0    0.0     0.0     0.0   \n",
       "2      0.0    0.0   0.0  0.0   0.0     0.0      0.0    0.0     0.0     0.0   \n",
       "3      0.0    0.0   0.0  0.0   0.0     0.0      0.0    0.0     0.0     0.0   \n",
       "4      0.0    0.0   0.0  0.0   0.0     0.0      0.0    0.0     0.0     0.0   \n",
       "\n",
       "   zeppelin  zest  zip  zodiac  zone  zoo  zoological  zoology  zoom  \n",
       "0       0.0   0.0  0.0     0.0   0.0  0.0         0.0      0.0   0.0  \n",
       "1       0.0   0.0  0.0     0.0   0.0  0.0         0.0      0.0   0.0  \n",
       "2       0.0   0.0  0.0     0.0   0.0  0.0         0.0      0.0   0.0  \n",
       "3       0.0   0.0  0.0     0.0   0.0  0.0         0.0      0.0   0.0  \n",
       "4       0.0   0.0  0.0     0.0   0.0  0.0         0.0      0.0   0.0  \n",
       "\n",
       "[5 rows x 14181 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#CountVectorizer(stop_words='english', binary=True)\n",
    "# I only want you to look for words in the emotional lexicon\n",
    "# because we don't know what's up with the other words\n",
    "vec = TfidfVectorizer(vocabulary=emolex_df.word,\n",
    "                      use_idf=False, \n",
    "                      norm= None ) #'l1') # ELL - ONE\n",
    "matrix = vec.fit_transform(df['lemmatized'])\n",
    "vocab = vec.get_feature_names()\n",
    "wordcount_df = pd.DataFrame(matrix.toarray(), columns=vocab)\n",
    "wordcount_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>emotion</th>\n",
       "      <th>word</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abacus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abandon</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandonment</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "emotion         word  anger  anticipation  disgust  fear  joy  negative  \\\n",
       "0                NaN    0.0           0.0      0.0   0.0  0.0       0.0   \n",
       "1             abacus    NaN           NaN      NaN   NaN  NaN       NaN   \n",
       "2            abandon    0.0           0.0      0.0   1.0  0.0       1.0   \n",
       "3          abandoned    1.0           0.0      0.0   1.0  0.0       1.0   \n",
       "4        abandonment    1.0           0.0      0.0   1.0  0.0       1.0   \n",
       "\n",
       "emotion  positive  sadness  surprise  trust  \n",
       "0             0.0      0.0       0.0    0.0  \n",
       "1             NaN      0.0       0.0    1.0  \n",
       "2             0.0      1.0       0.0    0.0  \n",
       "3             0.0      1.0       0.0    0.0  \n",
       "4             0.0      1.0       1.0    0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emolex_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>emotion</th>\n",
       "      <th>word</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandoned</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandonment</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>abhor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>abhorrent</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>abolish</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "emotion         word  anger  anticipation  disgust  fear  joy  negative  \\\n",
       "3          abandoned    1.0           0.0      0.0   1.0  0.0       1.0   \n",
       "4        abandonment    1.0           0.0      0.0   1.0  0.0       1.0   \n",
       "17             abhor    1.0           0.0      1.0   1.0  0.0       1.0   \n",
       "18         abhorrent    1.0           0.0      1.0   1.0  0.0       1.0   \n",
       "27           abolish    1.0           0.0      0.0   0.0  0.0       1.0   \n",
       "\n",
       "emotion  positive  sadness  surprise  trust  \n",
       "3             0.0      1.0       0.0    0.0  \n",
       "4             0.0      1.0       1.0    0.0  \n",
       "17            0.0      0.0       0.0    0.0  \n",
       "18            0.0      0.0       0.0    0.0  \n",
       "27            0.0      0.0       0.0    0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emolex_df[emolex_df.anger == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your list of positive words\n",
    "\n",
    "angry_words = emolex_df[emolex_df.anger == 1]['word']\n",
    "\n",
    "positive_words = emolex_df[emolex_df.positive == 1]['word']\n",
    "\n",
    "\n",
    "# Get your list of sadness words\n",
    "sadness_words = emolex_df[emolex_df.sadness == 1]['word']\n",
    "\n",
    "\n",
    "# Get your list of surprise words\n",
    "surprise_words = emolex_df[emolex_df.surprise == 1]['word']\n",
    "\n",
    "\n",
    "# Get your list of disgust words\n",
    "disgust_words = emolex_df[emolex_df.disgust == 1]['word']\n",
    "\n",
    "\n",
    "# Get your list of anticipation words\n",
    "anticipation_words = emolex_df[emolex_df.anticipation == 1]['word']\n",
    "\n",
    "\n",
    "# Get your list of negative words\n",
    "negative_words = emolex_df[emolex_df.negative == 1]['word']\n",
    "\n",
    "\n",
    "\n",
    "# Get your list of joy words\n",
    "joy_words = emolex_df[emolex_df.joy == 1]['word']\n",
    "\n",
    "\n",
    "# Get your list of trust words\n",
    "trust_words = emolex_df[emolex_df.trust == 1]['word']\n",
    "\n",
    "\n",
    "\n",
    "# Get your list of fear words\n",
    "fear_words = emolex_df[emolex_df.fear == 1]['word']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['anger'] = (wordcount_df[angry_words].sum(axis=1) / df['uniq_wds']) *100\n",
    "\n",
    "df['positivity'] = (wordcount_df[positive_words].sum(axis=1) / df['uniq_wds']) *100\n",
    "\n",
    "\n",
    "df['joy'] = (wordcount_df[joy_words].sum(axis=1) / df['uniq_wds']) *100\n",
    "\n",
    "\n",
    "df['disgust'] = (wordcount_df[disgust_words].sum(axis=1) / df['uniq_wds']) *100\n",
    "\n",
    "\n",
    "\n",
    "df['surprise'] = (wordcount_df[surprise_words].sum(axis=1) / df['uniq_wds']) *100\n",
    "\n",
    "df['trust'] = (wordcount_df[trust_words].sum(axis=1) / df['uniq_wds']) *100\n",
    "\n",
    "\n",
    "df['anticipation'] = (wordcount_df[anticipation_words].sum(axis=1) / df['uniq_wds']) *100\n",
    "\n",
    "\n",
    "df['sadness'] = (wordcount_df[sadness_words].sum(axis=1) / df['uniq_wds']) *100\n",
    "\n",
    "df['negative'] = (wordcount_df[negative_words].sum(axis=1) / df['uniq_wds']) *100\n",
    "\n",
    "df['fear'] = (wordcount_df[fear_words].sum(axis=1) / df['uniq_wds']) *100\n",
    "\n",
    "df['density'] = df['positivity'] + df['negative']\n",
    "\n",
    "#df['joysad'] = np.where(df['joy']> df['sadness'], 1, 0)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12.048193\n",
       "1     0.684932\n",
       "2     1.463415\n",
       "3     4.545455\n",
       "4     6.024096\n",
       "Name: anger, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['anger'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "      <th>tag</th>\n",
       "      <th>df</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>num_wds</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>uniq_wds</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>char_count</th>\n",
       "      <th>numbers</th>\n",
       "      <th>mtld</th>\n",
       "      <th>msttr</th>\n",
       "      <th>hdd</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>perc_uniq</th>\n",
       "      <th>avg_sent</th>\n",
       "      <th>caps_body</th>\n",
       "      <th>title_polarity</th>\n",
       "      <th>anger</th>\n",
       "      <th>positivity</th>\n",
       "      <th>joy</th>\n",
       "      <th>disgust</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>sadness</th>\n",
       "      <th>negative</th>\n",
       "      <th>fear</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2bdc29d12605ef9cf3f09f9875040a7113be5d5b</td>\n",
       "      <td>reasoning with facts</td>\n",
       "      <td>2016-10-29 08:47:11.259000+03:00</td>\n",
       "      <td>Why Did Attorney General Loretta Lynch Plead T...</td>\n",
       "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>bias</td>\n",
       "      <td>grafn</td>\n",
       "      <td>why did attorney general loretta lynch plead t...</td>\n",
       "      <td>277</td>\n",
       "      <td>39</td>\n",
       "      <td>166</td>\n",
       "      <td>why did attorney general loretta lynch plead t...</td>\n",
       "      <td>1732</td>\n",
       "      <td>1</td>\n",
       "      <td>13.459502</td>\n",
       "      <td>0.545882</td>\n",
       "      <td>0.397903</td>\n",
       "      <td>5.447653</td>\n",
       "      <td>0.599278</td>\n",
       "      <td>5.447653</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>12.048193</td>\n",
       "      <td>14.457831</td>\n",
       "      <td>4.216867</td>\n",
       "      <td>6.626506</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>13.253012</td>\n",
       "      <td>6.024096</td>\n",
       "      <td>5.421687</td>\n",
       "      <td>16.265060</td>\n",
       "      <td>13.253012</td>\n",
       "      <td>30.722892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>c70e149fdd53de5e61c29281100b9de0ed268bc3</td>\n",
       "      <td>Barracuda Brigade</td>\n",
       "      <td>2016-10-31 01:41:49.479000+02:00</td>\n",
       "      <td>Red State :  Fox News Sunday reported this mor...</td>\n",
       "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>bias</td>\n",
       "      <td>grafn</td>\n",
       "      <td>red state fox news sunday reported this mornin...</td>\n",
       "      <td>222</td>\n",
       "      <td>44</td>\n",
       "      <td>146</td>\n",
       "      <td>red state fox news sunday reported this mornin...</td>\n",
       "      <td>1316</td>\n",
       "      <td>0</td>\n",
       "      <td>12.923091</td>\n",
       "      <td>0.535686</td>\n",
       "      <td>0.382681</td>\n",
       "      <td>5.066964</td>\n",
       "      <td>0.657658</td>\n",
       "      <td>5.066964</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.684932</td>\n",
       "      <td>8.904110</td>\n",
       "      <td>2.739726</td>\n",
       "      <td>0.684932</td>\n",
       "      <td>0.684932</td>\n",
       "      <td>8.904110</td>\n",
       "      <td>4.109589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>0.684932</td>\n",
       "      <td>10.273973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0206b54719c7e241ffe0ad4315b808290dbe6c0f</td>\n",
       "      <td>Fed Up</td>\n",
       "      <td>2016-11-01 21:56:00+02:00</td>\n",
       "      <td>Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...</td>\n",
       "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>bias</td>\n",
       "      <td>grafn</td>\n",
       "      <td>email healthcare reform to make america great ...</td>\n",
       "      <td>332</td>\n",
       "      <td>43</td>\n",
       "      <td>205</td>\n",
       "      <td>email healthcare reform to make america great ...</td>\n",
       "      <td>2053</td>\n",
       "      <td>0</td>\n",
       "      <td>13.212205</td>\n",
       "      <td>0.534500</td>\n",
       "      <td>0.393574</td>\n",
       "      <td>5.295181</td>\n",
       "      <td>0.617470</td>\n",
       "      <td>5.295181</td>\n",
       "      <td>6</td>\n",
       "      <td>0.7111</td>\n",
       "      <td>1.463415</td>\n",
       "      <td>10.731707</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>2.926829</td>\n",
       "      <td>1.951220</td>\n",
       "      <td>7.317073</td>\n",
       "      <td>3.902439</td>\n",
       "      <td>3.414634</td>\n",
       "      <td>7.804878</td>\n",
       "      <td>1.951220</td>\n",
       "      <td>18.536585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>8f30f5ea14c9d5914a9fe4f55ab2581772af4c31</td>\n",
       "      <td>Barracuda Brigade</td>\n",
       "      <td>2016-11-02 16:31:28.550000+02:00</td>\n",
       "      <td>Print Hillary goes absolutely berserk! She exp...</td>\n",
       "      <td>Hillary Goes Absolutely Berserk On Protester A...</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>bias</td>\n",
       "      <td>grafn</td>\n",
       "      <td>print hillary goes absolutely berserk she expl...</td>\n",
       "      <td>178</td>\n",
       "      <td>42</td>\n",
       "      <td>110</td>\n",
       "      <td>print hillary go absolutely berserk she explod...</td>\n",
       "      <td>1174</td>\n",
       "      <td>3</td>\n",
       "      <td>13.387537</td>\n",
       "      <td>0.541739</td>\n",
       "      <td>0.413866</td>\n",
       "      <td>5.836066</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>5.836066</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>2.727273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>2.727273</td>\n",
       "      <td>2.727273</td>\n",
       "      <td>2.727273</td>\n",
       "      <td>5.454545</td>\n",
       "      <td>14.545455</td>\n",
       "      <td>2.727273</td>\n",
       "      <td>17.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>d3cc0fe38f41a59f7c48f8c3528ca5f74193148f</td>\n",
       "      <td>Fed Up</td>\n",
       "      <td>2016-11-04 19:40:00+02:00</td>\n",
       "      <td>BREAKING! NYPD Ready To Make Arrests In Weiner...</td>\n",
       "      <td>BREAKING! NYPD Ready To Make Arrests In Weiner...</td>\n",
       "      <td>100percentfedup.com</td>\n",
       "      <td>bias</td>\n",
       "      <td>grafn</td>\n",
       "      <td>breaking nypd ready to make arrests in weiner ...</td>\n",
       "      <td>955</td>\n",
       "      <td>47</td>\n",
       "      <td>415</td>\n",
       "      <td>breaking nypd ready to make arrest in weiner c...</td>\n",
       "      <td>5630</td>\n",
       "      <td>3</td>\n",
       "      <td>13.120733</td>\n",
       "      <td>0.532613</td>\n",
       "      <td>0.392665</td>\n",
       "      <td>5.080042</td>\n",
       "      <td>0.434555</td>\n",
       "      <td>5.080042</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1759</td>\n",
       "      <td>6.024096</td>\n",
       "      <td>20.963855</td>\n",
       "      <td>5.542169</td>\n",
       "      <td>5.060241</td>\n",
       "      <td>2.409639</td>\n",
       "      <td>14.216867</td>\n",
       "      <td>6.987952</td>\n",
       "      <td>3.614458</td>\n",
       "      <td>10.120482</td>\n",
       "      <td>6.024096</td>\n",
       "      <td>31.084337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                        id                author  \\\n",
       "0      1  2bdc29d12605ef9cf3f09f9875040a7113be5d5b  reasoning with facts   \n",
       "1      2  c70e149fdd53de5e61c29281100b9de0ed268bc3     Barracuda Brigade   \n",
       "2      4  0206b54719c7e241ffe0ad4315b808290dbe6c0f                Fed Up   \n",
       "3      5  8f30f5ea14c9d5914a9fe4f55ab2581772af4c31     Barracuda Brigade   \n",
       "4      6  d3cc0fe38f41a59f7c48f8c3528ca5f74193148f                Fed Up   \n",
       "\n",
       "                               date  \\\n",
       "0  2016-10-29 08:47:11.259000+03:00   \n",
       "1  2016-10-31 01:41:49.479000+02:00   \n",
       "2         2016-11-01 21:56:00+02:00   \n",
       "3  2016-11-02 16:31:28.550000+02:00   \n",
       "4         2016-11-04 19:40:00+02:00   \n",
       "\n",
       "                                                text  \\\n",
       "0  Why Did Attorney General Loretta Lynch Plead T...   \n",
       "1  Red State :  Fox News Sunday reported this mor...   \n",
       "2  Email HEALTHCARE REFORM TO MAKE AMERICA GREAT ...   \n",
       "3  Print Hillary goes absolutely berserk! She exp...   \n",
       "4  BREAKING! NYPD Ready To Make Arrests In Weiner...   \n",
       "\n",
       "                                               title               source  \\\n",
       "0  Re: Why Did Attorney General Loretta Lynch Ple...  100percentfedup.com   \n",
       "1  BREAKING: Weiner Cooperating With FBI On Hilla...  100percentfedup.com   \n",
       "2  FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...  100percentfedup.com   \n",
       "3  Hillary Goes Absolutely Berserk On Protester A...  100percentfedup.com   \n",
       "4  BREAKING! NYPD Ready To Make Arrests In Weiner...  100percentfedup.com   \n",
       "\n",
       "    tag     df                                          tokenized  num_wds  \\\n",
       "0  bias  grafn  why did attorney general loretta lynch plead t...      277   \n",
       "1  bias  grafn  red state fox news sunday reported this mornin...      222   \n",
       "2  bias  grafn  email healthcare reform to make america great ...      332   \n",
       "3  bias  grafn  print hillary goes absolutely berserk she expl...      178   \n",
       "4  bias  grafn  breaking nypd ready to make arrests in weiner ...      955   \n",
       "\n",
       "   difficulty  uniq_wds                                         lemmatized  \\\n",
       "0          39       166  why did attorney general loretta lynch plead t...   \n",
       "1          44       146  red state fox news sunday reported this mornin...   \n",
       "2          43       205  email healthcare reform to make america great ...   \n",
       "3          42       110  print hillary go absolutely berserk she explod...   \n",
       "4          47       415  breaking nypd ready to make arrest in weiner c...   \n",
       "\n",
       "   char_count  numbers       mtld     msttr       hdd  avg_word  perc_uniq  \\\n",
       "0        1732        1  13.459502  0.545882  0.397903  5.447653   0.599278   \n",
       "1        1316        0  12.923091  0.535686  0.382681  5.066964   0.657658   \n",
       "2        2053        0  13.212205  0.534500  0.393574  5.295181   0.617470   \n",
       "3        1174        3  13.387537  0.541739  0.413866  5.836066   0.617978   \n",
       "4        5630        3  13.120733  0.532613  0.392665  5.080042   0.434555   \n",
       "\n",
       "   avg_sent  caps_body  title_polarity      anger  positivity       joy  \\\n",
       "0  5.447653          0          0.0000  12.048193   14.457831  4.216867   \n",
       "1  5.066964          0          0.0000   0.684932    8.904110  2.739726   \n",
       "2  5.295181          6          0.7111   1.463415   10.731707  0.975610   \n",
       "3  5.836066          0          0.0000   4.545455    2.727273  0.000000   \n",
       "4  5.080042          1          0.1759   6.024096   20.963855  5.542169   \n",
       "\n",
       "    disgust  surprise      trust  anticipation   sadness   negative  \\\n",
       "0  6.626506  0.602410  13.253012      6.024096  5.421687  16.265060   \n",
       "1  0.684932  0.684932   8.904110      4.109589  0.000000   1.369863   \n",
       "2  2.926829  1.951220   7.317073      3.902439  3.414634   7.804878   \n",
       "3  4.545455  2.727273   2.727273      2.727273  5.454545  14.545455   \n",
       "4  5.060241  2.409639  14.216867      6.987952  3.614458  10.120482   \n",
       "\n",
       "        fear    density  \n",
       "0  13.253012  30.722892  \n",
       "1   0.684932  10.273973  \n",
       "2   1.951220  18.536585  \n",
       "3   2.727273  17.272727  \n",
       "4   6.024096  31.084337  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/medium/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "for i in range(df.shape[0]): \n",
    "    df.loc[i, \"polarity\"] = abs(sid.polarity_scores(df.loc[i, 'lemmatized'])['compound'])\n",
    "    df.loc[i, \"negativity_vader\"] = abs(sid.polarity_scores(df.loc[i, 'lemmatized'])['neg'])\n",
    "    df.loc[i, \"neutrality_vader\"] = abs(sid.polarity_scores(df.loc[i, 'lemmatized'])['neu'])\n",
    "    df.loc[i, \"positivity_vader\"] = abs(sid.polarity_scores(df.loc[i, 'lemmatized'])['pos'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 12 Subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from textblob import TextBlob, Word\n",
    "\n",
    "#def detect_polarity(text):\n",
    "#    return TextBlob(text).sentiment.polarity\n",
    "def detect_subjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subjectivity'] = df.lemmatized.apply(detect_subjectivity)\n",
    "#df['polarity_textblob'] = df.lemma_content.apply(detect_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "      <th>tag</th>\n",
       "      <th>df</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>num_wds</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>uniq_wds</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>char_count</th>\n",
       "      <th>numbers</th>\n",
       "      <th>mtld</th>\n",
       "      <th>msttr</th>\n",
       "      <th>hdd</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>perc_uniq</th>\n",
       "      <th>avg_sent</th>\n",
       "      <th>caps_body</th>\n",
       "      <th>title_polarity</th>\n",
       "      <th>anger</th>\n",
       "      <th>positivity</th>\n",
       "      <th>joy</th>\n",
       "      <th>disgust</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>sadness</th>\n",
       "      <th>negative</th>\n",
       "      <th>fear</th>\n",
       "      <th>density</th>\n",
       "      <th>polarity</th>\n",
       "      <th>negativity_vader</th>\n",
       "      <th>neutrality_vader</th>\n",
       "      <th>positivity_vader</th>\n",
       "      <th>subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48527</th>\n",
       "      <td>58100</td>\n",
       "      <td>1.96551e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-28 00:00:00</td>\n",
       "      <td>28-08-2016 Turkish Bombardment Kills 20 Civili...</td>\n",
       "      <td>Turkish Bombardment Kills 20 Civilians in Syria</td>\n",
       "      <td>manar</td>\n",
       "      <td>1</td>\n",
       "      <td>svdc</td>\n",
       "      <td>28082016 turkish bombardment kills 20 civilian...</td>\n",
       "      <td>240</td>\n",
       "      <td>40</td>\n",
       "      <td>114</td>\n",
       "      <td>28082016 turkish bombardment kill 20 civilian ...</td>\n",
       "      <td>1446</td>\n",
       "      <td>6</td>\n",
       "      <td>13.924646</td>\n",
       "      <td>0.555714</td>\n",
       "      <td>0.403273</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.526316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.754386</td>\n",
       "      <td>1.754386</td>\n",
       "      <td>2.631579</td>\n",
       "      <td>15.789474</td>\n",
       "      <td>13.157895</td>\n",
       "      <td>15.789474</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.213690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48528</th>\n",
       "      <td>58101</td>\n",
       "      <td>1.96551e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-01 00:00:00</td>\n",
       "      <td>17-08-2016 Martyrs as Terrorists Shell Aleppos...</td>\n",
       "      <td>Martyrs as Terrorists Shell Aleppos Salah Eddin</td>\n",
       "      <td>manar</td>\n",
       "      <td>1</td>\n",
       "      <td>svdc</td>\n",
       "      <td>17082016 martyrs as terrorists shell aleppos s...</td>\n",
       "      <td>113</td>\n",
       "      <td>33</td>\n",
       "      <td>64</td>\n",
       "      <td>17082016 martyr a terrorist shell aleppo salah...</td>\n",
       "      <td>726</td>\n",
       "      <td>1</td>\n",
       "      <td>12.476640</td>\n",
       "      <td>0.517143</td>\n",
       "      <td>0.395255</td>\n",
       "      <td>5.504425</td>\n",
       "      <td>0.566372</td>\n",
       "      <td>5.504425</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>14.062500</td>\n",
       "      <td>20.312500</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>23.437500</td>\n",
       "      <td>0.9861</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.258333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48529</th>\n",
       "      <td>58102</td>\n",
       "      <td>1.96551e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-03 00:00:00</td>\n",
       "      <td>03-08-2016 Chemical Attack Kills Five Syrians ...</td>\n",
       "      <td>Chemical Attack Kills Five Syrians in Aleppo SANA</td>\n",
       "      <td>manar</td>\n",
       "      <td>0</td>\n",
       "      <td>svdc</td>\n",
       "      <td>03082016 chemical attack kills five syrians in...</td>\n",
       "      <td>224</td>\n",
       "      <td>28</td>\n",
       "      <td>130</td>\n",
       "      <td>03082016 chemical attack kill five syrian in a...</td>\n",
       "      <td>1418</td>\n",
       "      <td>2</td>\n",
       "      <td>13.552202</td>\n",
       "      <td>0.539636</td>\n",
       "      <td>0.397377</td>\n",
       "      <td>5.388393</td>\n",
       "      <td>0.580357</td>\n",
       "      <td>5.388393</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.230769</td>\n",
       "      <td>4.615385</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>5.384615</td>\n",
       "      <td>3.076923</td>\n",
       "      <td>9.230769</td>\n",
       "      <td>17.692308</td>\n",
       "      <td>16.923077</td>\n",
       "      <td>22.307692</td>\n",
       "      <td>0.9865</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48530</th>\n",
       "      <td>58103</td>\n",
       "      <td>1.96551e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-01 00:00:00</td>\n",
       "      <td>01-08-2016 5 Killed as Russian Military Choppe...</td>\n",
       "      <td>5 Killed as Russian Military Chopper Shot down...</td>\n",
       "      <td>manar</td>\n",
       "      <td>1</td>\n",
       "      <td>svdc</td>\n",
       "      <td>01082016 5 killed as russian military chopper ...</td>\n",
       "      <td>244</td>\n",
       "      <td>44</td>\n",
       "      <td>121</td>\n",
       "      <td>01082016 5 killed a russian military chopper s...</td>\n",
       "      <td>1483</td>\n",
       "      <td>1</td>\n",
       "      <td>13.401570</td>\n",
       "      <td>0.535862</td>\n",
       "      <td>0.392486</td>\n",
       "      <td>5.159836</td>\n",
       "      <td>0.495902</td>\n",
       "      <td>5.159836</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.570248</td>\n",
       "      <td>15.702479</td>\n",
       "      <td>4.132231</td>\n",
       "      <td>1.652893</td>\n",
       "      <td>5.785124</td>\n",
       "      <td>13.223140</td>\n",
       "      <td>7.438017</td>\n",
       "      <td>9.917355</td>\n",
       "      <td>9.090909</td>\n",
       "      <td>13.223140</td>\n",
       "      <td>24.793388</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.177183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48531</th>\n",
       "      <td>58104</td>\n",
       "      <td>1.96551e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-04-04 00:00:00</td>\n",
       "      <td>April 6 2017 Syrian Army Kills 48 ISIL Terrori...</td>\n",
       "      <td>Syrian Army Kills 48 ISIL Terrorists in Deir E...</td>\n",
       "      <td>manar</td>\n",
       "      <td>1</td>\n",
       "      <td>svdc</td>\n",
       "      <td>april 6 2017 syrian army kills 48 isil terrori...</td>\n",
       "      <td>408</td>\n",
       "      <td>21</td>\n",
       "      <td>173</td>\n",
       "      <td>april 6 2017 syrian army kill 48 isil terroris...</td>\n",
       "      <td>2565</td>\n",
       "      <td>8</td>\n",
       "      <td>12.903470</td>\n",
       "      <td>0.526800</td>\n",
       "      <td>0.386315</td>\n",
       "      <td>5.366748</td>\n",
       "      <td>0.424020</td>\n",
       "      <td>5.366748</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.075145</td>\n",
       "      <td>6.358382</td>\n",
       "      <td>3.468208</td>\n",
       "      <td>8.670520</td>\n",
       "      <td>10.404624</td>\n",
       "      <td>5.202312</td>\n",
       "      <td>3.468208</td>\n",
       "      <td>14.450867</td>\n",
       "      <td>21.965318</td>\n",
       "      <td>25.433526</td>\n",
       "      <td>28.323699</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.181270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index           id author                 date  \\\n",
       "48527  58100  1.96551e+09    NaN  2016-08-28 00:00:00   \n",
       "48528  58101  1.96551e+09    NaN  2016-08-01 00:00:00   \n",
       "48529  58102  1.96551e+09    NaN  2016-08-03 00:00:00   \n",
       "48530  58103  1.96551e+09    NaN  2016-08-01 00:00:00   \n",
       "48531  58104  1.96551e+09    NaN  2017-04-04 00:00:00   \n",
       "\n",
       "                                                    text  \\\n",
       "48527  28-08-2016 Turkish Bombardment Kills 20 Civili...   \n",
       "48528  17-08-2016 Martyrs as Terrorists Shell Aleppos...   \n",
       "48529  03-08-2016 Chemical Attack Kills Five Syrians ...   \n",
       "48530  01-08-2016 5 Killed as Russian Military Choppe...   \n",
       "48531  April 6 2017 Syrian Army Kills 48 ISIL Terrori...   \n",
       "\n",
       "                                                   title source tag    df  \\\n",
       "48527    Turkish Bombardment Kills 20 Civilians in Syria  manar   1  svdc   \n",
       "48528    Martyrs as Terrorists Shell Aleppos Salah Eddin  manar   1  svdc   \n",
       "48529  Chemical Attack Kills Five Syrians in Aleppo SANA  manar   0  svdc   \n",
       "48530  5 Killed as Russian Military Chopper Shot down...  manar   1  svdc   \n",
       "48531  Syrian Army Kills 48 ISIL Terrorists in Deir E...  manar   1  svdc   \n",
       "\n",
       "                                               tokenized  num_wds  difficulty  \\\n",
       "48527  28082016 turkish bombardment kills 20 civilian...      240          40   \n",
       "48528  17082016 martyrs as terrorists shell aleppos s...      113          33   \n",
       "48529  03082016 chemical attack kills five syrians in...      224          28   \n",
       "48530  01082016 5 killed as russian military chopper ...      244          44   \n",
       "48531  april 6 2017 syrian army kills 48 isil terrori...      408          21   \n",
       "\n",
       "       uniq_wds                                         lemmatized  \\\n",
       "48527       114  28082016 turkish bombardment kill 20 civilian ...   \n",
       "48528        64  17082016 martyr a terrorist shell aleppo salah...   \n",
       "48529       130  03082016 chemical attack kill five syrian in a...   \n",
       "48530       121  01082016 5 killed a russian military chopper s...   \n",
       "48531       173  april 6 2017 syrian army kill 48 isil terroris...   \n",
       "\n",
       "       char_count  numbers       mtld     msttr       hdd  avg_word  \\\n",
       "48527        1446        6  13.924646  0.555714  0.403273  5.125000   \n",
       "48528         726        1  12.476640  0.517143  0.395255  5.504425   \n",
       "48529        1418        2  13.552202  0.539636  0.397377  5.388393   \n",
       "48530        1483        1  13.401570  0.535862  0.392486  5.159836   \n",
       "48531        2565        8  12.903470  0.526800  0.386315  5.366748   \n",
       "\n",
       "       perc_uniq  avg_sent  caps_body  title_polarity      anger  positivity  \\\n",
       "48527   0.475000  5.125000          0             NaN  10.526316    0.000000   \n",
       "48528   0.566372  5.504425          0             NaN  12.500000    3.125000   \n",
       "48529   0.580357  5.388393          0             NaN   9.230769    4.615385   \n",
       "48530   0.495902  5.159836          0             NaN  11.570248   15.702479   \n",
       "48531   0.424020  5.366748          1             NaN  19.075145    6.358382   \n",
       "\n",
       "            joy   disgust   surprise      trust  anticipation    sadness  \\\n",
       "48527  0.000000  0.000000   0.000000   1.754386      1.754386   2.631579   \n",
       "48528  1.562500  6.250000   6.250000   1.562500      6.250000  14.062500   \n",
       "48529  1.538462  2.307692   2.307692   5.384615      3.076923   9.230769   \n",
       "48530  4.132231  1.652893   5.785124  13.223140      7.438017   9.917355   \n",
       "48531  3.468208  8.670520  10.404624   5.202312      3.468208  14.450867   \n",
       "\n",
       "        negative       fear    density  polarity  negativity_vader  \\\n",
       "48527  15.789474  13.157895  15.789474    0.9681             0.126   \n",
       "48528  20.312500  18.750000  23.437500    0.9861             0.248   \n",
       "48529  17.692308  16.923077  22.307692    0.9865             0.172   \n",
       "48530   9.090909  13.223140  24.793388    0.9744             0.121   \n",
       "48531  21.965318  25.433526  28.323699    0.9991             0.263   \n",
       "\n",
       "       neutrality_vader  positivity_vader  subjectivity  \n",
       "48527             0.839             0.036      0.213690  \n",
       "48528             0.752             0.000      0.258333  \n",
       "48529             0.803             0.024      0.285000  \n",
       "48530             0.838             0.042      0.177183  \n",
       "48531             0.690             0.047      0.181270  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'id', 'author', 'date', 'text', 'title', 'source', 'tag', 'df',\n",
       "       'tokenized', 'num_wds', 'difficulty', 'uniq_wds', 'lemmatized',\n",
       "       'char_count', 'numbers', 'mtld', 'msttr', 'hdd', 'avg_word',\n",
       "       'perc_uniq', 'avg_sent', 'caps_body', 'anger', 'positivity', 'joy',\n",
       "       'disgust', 'surprise', 'trust', 'anticipation', 'sadness', 'negative',\n",
       "       'fear', 'density', 'sad', 'happy', 'inspired', 'dont_care', 'annoyed',\n",
       "       'amused', 'afraid', 'polarity', 'negativity_vader', 'neutrality_vader',\n",
       "       'positivity_vader', 'subjectivity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"fakenews2.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
